# -*- coding: utf-8 -*-
"""lyrics_generator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DEHYs11s_EyfBMd2yTUheUcDrYy0XCOv

# Lyrics Generator
Is an NLP model that is used to create the lyrics of the words given as input using LSTM in it on Tensorflow.

# 1.Aim
The aim is to create a lyrics inducer for any word given as th input and output as the set of words which which will be the lyrics of the song.

# 2.Setup
"""

from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
import tensorflow.keras.utils as ku
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

"""# 3. Importing the dataset"""

lyric=open('/content/lorde.txt').read()
lyric[:2000]

"""# 4.Pre processing"""

corpus=lyric.lower().split('\n')
for i in range(40,60):
    print(corpus[i])

"""# 5.Code mounting drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# 6.Tokenizing"""

tokenizer = Tokenizer()
tokenizer.fit_on_texts(corpus)
total_words = len(tokenizer.word_index) + 1
total_words

"""# 7.Creating Sequences"""

input_sequences = []
for line in corpus:
  token_list = tokenizer.texts_to_sequences([line])[0]
  for i in range(1, len(token_list)):
    n_gram_sequence = token_list[:i+1]
    input_sequences.append(n_gram_sequence)

for i in range(20):
    print(input_sequences[i])

"""# 8.Padding"""

max_sequence_len = max([len(x) for x in input_sequences])
input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len,
padding='pre'))
print(max_sequence_len)
print(input_sequences)

"""# 9.Building the model"""

model = Sequential()
model.add(Embedding(1372, 160, input_length=max_sequence_len-1))
model.add(Bidirectional(LSTM(200, return_sequences = True)))
model.add(Dropout(0.2))
model.add(LSTM(100))
model.add(Dense(1372/2, activation='relu', kernel_regularizer=regularizers.l2(0.001
)))
model.add(Dense(1372, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

predictors, label = input_sequences[:,:-1],input_sequences[:,-1]
label = ku.to_categorical(label, num_classes=total_words)

"""# 10. Training the model"""

history = model.fit(predictors, label, epochs=50, verbose=1)

"""# 11.Analysing the results"""

acc = history.history['accuracy']
loss = history.history['loss']
epochs = range(len(acc))
plt.plot(epochs, acc, 'b', label='Training accuracy')
plt.title('Training accuracy')
plt.figure()
plt.plot(epochs, loss, 'b', label='Training Loss')
plt.title('Training loss')
plt.legend()
plt.show()

"""# 12.Saving the model"""

model.save('lyrics_generator.h5')

"""# 13.Loading the model"""

from keras.models import load_model
loaded_model=load_model('lyrics_generator.h5')

next_words=50
seed_text='diamond in the flash'

def lyrics(next_words,seed_text):
  for _ in range(next_words):
    token_list = tokenizer.texts_to_sequences([seed_text])[0]
    token_list = pad_sequences([token_list], maxlen=max_sequence_len-
  1, padding='pre')
    predicted = np.argmax(loaded_model.predict(token_list, verbose=0), axis=-1)
    output_word = ""
    for word, index in tokenizer.word_index.items():
      if index == predicted:
        output_word = word
        break
    seed_text += " " + output_word
  print(seed_text)

lyrics(next_words,seed_text)

"""# Saving the model in json"""

import time
saved_model_path = "./{}.h5".format(int(time.time()))
model.save(saved_model_path)

!pip install tensorflowjs

import tensorflowjs

!tensorflowjs_converter --input_format=keras {saved_model_path} ./

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
model.save_weights("model.h5")
print("Saved model to disk")

"""# Loading the model from json"""

from keras.models import model_from_json
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights("model.h5")
print("Loaded model from disk")

loaded_model.summary()

next_words = 100
seed_text = "diamond in the flash"

def lyrics(next_words,seed_text):
  for _ in range(next_words):
    token_list = tokenizer.texts_to_sequences([seed_text])[0]
    token_list = pad_sequences([token_list], maxlen=max_sequence_len-
  1, padding='pre')
    predicted = np.argmax(loaded_model.predict(token_list, verbose=0), axis=-1)
    output_word = ""
    for word, index in tokenizer.word_index.items():
      if index == predicted:
        output_word = word
        break
    seed_text += " " + output_word
  print(seed_text)

lyrics(next_words,seed_text)

next_words=50

seed_text

seed_text="hey you are a"

lyrics(next_words,seed_text)

